# Lesson 06: Webscraping

## Getting to Know `WGET`

Here we will discuss webscraping --- the main process of efficiently collecting large volumes of information from the Internet.

## Software

* `wget` (<https://www.gnu.org/software/wget/>), a free software package for retrieving files using HTTP, HTTPS, FTP and FTPS the most widely-used Internet protocols. It is a non-interactive command line tool, so it may easily be called from scripts, cron jobs, terminals without X-Windows support, etc.

* **NB**: on installing `wget`:
	* On Windows (the easiest): download from <https://eternallybored.org/misc/wget/> > choose the latest 64-bit ZIP file (`EXE` will most likely be blocked by your browser as a potentially dangerous file).
		* Unzip the file and copy `wget.exe` to the folder where you are planning to scrape data; *NB:* the easiest approach on Windows is to move/copy this file into relevant folders. 
	* On Mac (and, possibly, Linux): `brew install wget`

## Class

* practical examples of working with `wget`
* single link download
* batch download
	* web-page analysis
	* extraction of links with `regular expressions`
	* modification of links with `regular expressions`

## Sample commands

```
wget link
wget -i file_with_links.txt
wget -i file_with_links.txt -P ./folderYouWantToSaveTo/ -nc 
```

<!--
1. The first command will simply download a file specified in the link;
2. The second command will go over all links given in the `file_with_links.txt` --- in this file links must be stored one per line;
3. The third command also redirects downloaded results to a subfolder (`-p ./folderYouWantToSaveTo/`, where `-p` is an argument that specifies that `./folderYouWantToSaveTo/` is a folder for saved results; `-nc` is another useful argument, which tells `wget` not to download file if is already exists in the folder --- this command allows you to stop and restart downloading from where you stopped);
-->

Where:

* `-P` is a folder parameter, which instructs `wget` where you want to store downloaded files (*optional*).
* `-nc` is a *no-clobber* parameter, which instructs `wget` to skips files, if they already exist (*optional*)

Link examples:

```
https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_01.txt
https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_02.txt
https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_03.txt
```

**NB:** there are many other parameters with which you can adjust `wget` to your needs.

### Issues with `WGET` on Windows

As we have run into a number of issues with trying to run `WGET` on Windows, here are some steps that will help to run it smoothly:

- first of all, `WGET` does not seem to play well with `Powershell`; it does work without any problems via `Command Prompt` (if your Windows “speaks” German, it is called *Eingabeaufforderung*; but if you search for `Command Prompt`, you should still be able to find it.). It also works without any issues via `Git-Bash`. The following steps will make it easier to use with both `Command Prompt` and `Git-Bash`.
- download the `wget.exe` file (from here: <https://eternallybored.org/misc/wget/>);
- copy/paste it into the `C:\Windows\System32` folder (`C:\Windows\System32` is a part of the so-called `PATH` --- a series of paths which all Windows command line tools *check*);
- now, all the commands should be working as expected;

**NB:** There is an alternative to `WGET` on Windows `Powershell`. Here is a detailed tutorial: https://adamtheautomator.com/powershell-download-file/.

### Issues with `WGET` on Mac

It may so happen that `WGET` will not work as intended with the homework assignment (specifically, you may not be able to download all the issues of *Dispatch*). From what I understand this is specifically a Mac issue. Last year the MacOS changed their main command line program from `bash` to `zsh`, and in some cases `WGET` may not work as intended under `zsh`. The solution is, luckily, rather simple: we just need to install `bash` and run `WGET` from `bash`.

- to install `bash`, run `brew install bash`;
- after that you can start `bash` by running `bash` on the command line; the prompt (the beginning of the command line where you type in your commands) should change into something like: `bash-5.1$`
- now you can go to a folder where you want to save your downloaded results and run `WGET`;
- **NB:** you will need `bash` only for this step; after you restart the `Terminal`, you will be back to the default `zsh` (you can also run `exit` command to quit `bash` and return to `zsh`).

## A sidenote on issues in general

Keep in mind that one of the most important things that you need to learn in this course is that there are multiple solutions to most of the problems and tasks that you may face and the most common way to solve your problem is to break is down into smaller tasks (remember, there was a detailed discussion of this in Zelle’s book), and then look for efficient solutions to each step. No matter how advanced you are, “googling” will be the major way of finding suitable solutions.

## Practicing Scraping

The following sections give you some examples of links that you are most likely to encounter in real life. Your task is to figure out how to prepare lists of links (URLs) for downloading with `WGET`. Your first step will be to look under the hood of the current page, which you can do right clicking on the page and selecting something that looks like “View page source” (in Chrome or Edge) or “Show Page Source” (in Safari; you will need to enable “Show Develop menu in menu bar” in Preferences > Advanced). Now, looking at the HTML code of the page you can find the actual URLs, which you can then extract from the HTML code with regular expressions (one thing you can do is to `copy/paste` the entire code of the page into a text editor that supports regular expressions---like *Sublime Text*). 

## Practice 1: very easy

* [Article 01](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_01.txt)
* [Article 02](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_02.txt)
* [Article 03](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_03.txt)
* [Article 04](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_04.txt)
* [Article 05](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_05.txt)
* [Article 06](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_06.txt)
* [Article 07](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_07.txt)
* [Article 08](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_08.txt)
* [Article 09](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_09.txt)
* [Article 10](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_10.txt)
* [Article 11](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_11.txt)
* [Article 12](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_12.txt)
* [Article 13](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_13.txt)
* [Article 14](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_14.txt)
* [Article 15](https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_15.txt)

<!--
* [Article 01](./files/articles/1860-11-12_article_01.txt)
* [Article 02](./files/articles/1860-11-12_article_02.txt)
* [Article 03](./files/articles/1860-11-12_article_03.txt)
* [Article 04](./files/articles/1860-11-12_article_04.txt)
* [Article 05](./files/articles/1860-11-12_article_05.txt)
* [Article 06](./files/articles/1860-11-12_article_06.txt)
* [Article 07](./files/articles/1860-11-12_article_07.txt)
* [Article 08](./files/articles/1860-11-12_article_08.txt)
* [Article 09](./files/articles/1860-11-12_article_09.txt)
* [Article 10](./files/articles/1860-11-12_article_10.txt)
* [Article 11](./files/articles/1860-11-12_article_11.txt)
* [Article 12](./files/articles/1860-11-12_article_12.txt)
* [Article 13](./files/articles/1860-11-12_article_13.txt)
* [Article 14](./files/articles/1860-11-12_article_14.txt)
* [Article 15](./files/articles/1860-11-12_article_15.txt)
-->

## Practice 2: easy-ish

* [Article 16](./files/articles/1860-11-12_article_16.txt)
* [Article 17](./files/articles/1860-11-12_article_17.txt)
* [Article 18](./files/articles/1860-11-12_article_18.txt)
* [Article 19](./files/articles/1860-11-12_article_19.txt)
* [Article 20](./files/articles/1860-11-12_article_20.txt)
* [Article 21](./files/articles/1860-11-12_article_21.txt)
* [Article 22](./files/articles/1860-11-12_article_22.txt)
* [Article 23](./files/articles/1860-11-12_article_23.txt)
* [Article 24](./files/articles/1860-11-12_article_24.txt)
* [Article 25](./files/articles/1860-11-12_article_25.txt)
* [Article 26](./files/articles/1860-11-12_article_26.txt)
* [Article 27](./files/articles/1860-11-12_article_27.txt)
* [Article 28](./files/articles/1860-11-12_article_28.txt)
* [Article 29](./files/articles/1860-11-12_article_29.txt)
* [Article 30](./files/articles/1860-11-12_article_30.txt)
* [Article 31](./files/articles/1860-11-12_article_31.txt)
* [Article 32](./files/articles/1860-11-12_article_32.txt)
* [Article 33](./files/articles/1860-11-12_article_33.txt)
* [Article 34](./files/articles/1860-11-12_article_34.txt)
* [Article 35](./files/articles/1860-11-12_article_35.txt)
* [Article 36](./files/articles/1860-11-12_article_36.txt)
* [Article 37](./files/articles/1860-11-12_article_37.txt)
* [Article 38](./files/articles/1860-11-12_article_38.txt)
* [Article 39](./files/articles/1860-11-12_article_39.txt)

## Practice 3 (aka *Homework*): a tiny-bit tricky

* download issues of “Richmond Times Dispatch” (Years 1860-1865, only!), which are available at: <http://www.perseus.tufts.edu/hopper/collection?collection=Perseus:collection:RichTimes>)

## Reference Materials{#RML06}

* Milligan, Ian. 2012. “Automated Downloading with Wget.” Programming Historian, June. <https://programminghistorian.org/lessons/automated-downloading-with-wget>.
* Kurschinski, Kellen. 2013. “Applied Archival Downloading with Wget.” Programming Historian, September. <https://programminghistorian.org/lessons/applied-archival-downloading-with-wget>.
* Baxter, Richard. 2019. “How to download your website using WGET for Windows.” <https://builtvisible.com/download-your-website-with-wget/>.
* Alternatively, this operation can be done with a Python script: Turkel, William J., and Adam Crymble. 2012. “Downloading Web Pages with Python.” Programming Historian, July. <https://programminghistorian.org/lessons/working-with-web-pages>.

## Homework{#HWL06}

1. Scraping the “Dispatch”: download issues of “Richmond Times Dispatch” (Years 1860-1865, only!), which are available at: <http://www.perseus.tufts.edu/hopper/collection?collection=Perseus:collection:RichTimes>)
2. In a separate markdown file, describe your steps of how you completed this task (to be uloaded with the rest of your homework).

**Python**

- Work through Chapters 8 and 11 of Zelle's book; read chapters carefully; work through the chapter summaries and exercises; complete the following programming exercises: 1-8 in Chapter 8 and 1-11 in Chapter 11;
- Watch [Dr. Vierthaler's videos](https://www.youtube.com/playlist?list=PL6kqrM2i6BPIpEF5yHPNkYhjHm-FYWh17):
	- Episode 12: Functions
	- Episode 13: Libraries and NLTK
	- Episode 14: Regular Expressions
- **Note:** the sequences are somewhat different in Zelle's textbook and Vierthaler's videos. I would recommend you to always check Vierthaler's videos and also check videos which cover topics that you read about in Zelle's book.

## Submitting homework{#SHL06}

* Homework assignment must be submitted by the beginning of the next class;
* Email your homework to the instructor.
	* if your homework is to create a file, email it as an attachment
	* if your homework is a blogpost on your website, email the link to your website and to the blogpost with your homework.
	*  In the subject of your email, please, add the following: `070112-LXX-HW-YourLastName-YourMatriculationNumber`, where `LXX` is the lesson for which the homework is submitted, `YourLastName` is your last name, and `YourMatriculationNumber` is your matriculation number.